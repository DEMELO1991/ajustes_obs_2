# -*- coding: utf-8 -*-
"""Andreza_Exercicio_Avaliativo (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U_lCEbtPPu-H_ZBkT7TDfo8guZ_xBQmj

# Problema 1

Dado o modelo matem√°tico da equa√ß√£o normal da reta, a saber:

$x \cos(\theta) + y sen(\theta) - \rho = 0 \tag{A4} $

Considere que 2 pontos de coordenadas cartesianas foram observados $ n=10 $ vezes, e para cada observa√ß√£o foram atribu√≠das vari√¢ncias de diferentes qualidades.





### Resolu√ß√£o:
Baseado na sequ√™ncia de indaga√ß√µes apresentadas acima, tem-se que:
- As medidas observadas s√£o as coordenadas \( x \) e \( y \).
- Os par√¢metros a serem determinados s√£o os coeficientes \( \theta \) e \( \rho \).
- O modelo matem√°tico (\( F \)) √© impl√≠cito e n√£o linear.

| index |       x       |       y       |  rho_observed  |  variance  |
|-------|---------------|---------------|----------------|------------|
| 0     | -2.5092       | -9.5883       | -9.5671        | 1.1075     |
| 1     |  9.0143       |  9.3982       | 13.3339        | 0.6705     |
| 2     |  4.6399       |  6.6489       | 7.0744         | 0.5651     |
| 3     |  1.9732       | -5.7532       | -4.0852        | 1.4489     |
| 4     | -6.8796       | -6.3635       | -7.8986        | 1.4656     |
| 5     | -6.8801       | -6.3319       | -9.5681        | 1.3084     |
| 6     | -8.8383       | -3.9152       | -8.9506        | 0.8046     |
| 7     |  7.3235       |  0.4951       | 4.1038         | 0.5977     |
| 8     |  2.0223       | -1.3611       | -0.0768        | 1.1842     |
| 9     |  4.1615       | -4.1754       | 0.1011         | 0.9402     |

## Perguntas:

1. Quem s√£o as observa√ß√µes ou medidas e quais os par√¢metros a serem determinados?
"""

import pandas as pd

dados = {
    "index": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
    "x": [-2.5092, 9.0143, 4.6399, 1.9732, -6.8796, -6.8801, -8.8383, 7.3235, 2.0223, 4.1615],
    "y": [-9.5883, 9.3982, 6.6489, -5.7532, -6.3635, -6.3319, -3.9152, 0.4951, -1.3611, -4.1754],
    "rho_observed": [-9.5671, 13.3339, 7.0744, -4.0852, -7.8986, -9.5681, -8.9506, 4.1038, -0.0768, 0.1011],
    "variance": [1.1075, 0.6705, 0.5651, 1.4489, 1.4656, 1.3084, 0.8046, 0.5977, 1.1842, 0.9402]
}

df = pd.DataFrame(dados)

display(df)

"""Os **par√¢metros a serem determinados** no modelo s√£o:

- $\theta$ (√¢ngulo que a reta faz com o eixo horizontal)
- $\rho$ (dist√¢ncia perpendicular da reta √† origem)

Esses s√£o os coeficientes desconhecidos da equa√ß√£o normal da reta, dada por:

$$
x \cos(\theta) + y \sin(\theta) - \rho = 0
$$

As vari√°veis $x$ e $y$ s√£o observa√ß√µes (dados conhecidos), enquanto $\theta$ e $\rho$ s√£o os par√¢metros que precisam ser estimados.

2. O modelo matem√°tico $ F $ √© expl√≠cito ou impl√≠cito?

R: O modelo matem√°tico $F$ apresentado √© **impl√≠cito**.

Isso ocorre porque os par√¢metros $\theta$ e $\rho$ est√£o definidos implicitamente na equa√ß√£o:

$$x \cos(\theta) + y \sin(\theta) - \rho = 0$$

N√£o √© poss√≠vel isolar explicitamente as observa√ß√µes (x e y) em fun√ß√£o dos par√¢metros. Portanto, trata-se de um modelo impl√≠cito n√£o linear.
"""

# Modelo impl√≠cito da reta
def modelo_implicito(x, y, theta, rho):
    return x * np.cos(theta) + y * np.sin(theta) - rho

"""3. $ F $ √© linear ou n√£o linear?

R: O modelo matem√°tico $F$ apresentado √© **n√£o linear**.

Isto ocorre porque o par√¢metro $\theta$ est√° dentro das fun√ß√µes trigonom√©tricas $\sin(\theta)$ e $\cos(\theta)$, que n√£o s√£o lineares.

Explicitamente, o modelo √© dado por:
$$F(x, y, \theta, \rho) = x \cos(\theta) + y \sin(\theta) - \rho = 0$$

A presen√ßa das fun√ß√µes trigonom√©tricas de um par√¢metro torna o modelo n√£o linear com rela√ß√£o a $\theta$.
$$F(\theta, \rho) = x \cos(\theta) + y \sin(\theta) - \rho = 0
$$
"""

def F(theta, rho, x, y):
    return x * np.cos(theta) + y * np.sin(theta) - rho

"""4. Existe defici√™ncia de posto na matriz das equa√ß√µes normais $ N $?

# AVALIAR A QUALIDADE

## Calcular os par√¢metros
$ùúÉ
$ e
$
œÅ$ usando o m√©todo dos m√≠nimos quadrados ponderados.
"""

import numpy as np
import pandas as pd
from scipy.optimize import least_squares

# Criando corretamente o DataFrame
dados = pd.DataFrame({
    "x": [-2.5092, 9.0143, 4.6399, 1.9732, -6.8796, -6.8801, -8.8383, 7.3235, 2.0223, 4.1615],
    "y": [-9.5883, 9.3982, 6.6489, -5.7532, -6.3635, -6.3319, -3.9152, 0.4951, -1.3611, -4.1754],
    "rho_observed": [-9.5671, 13.3339, 7.0744, -4.0852, -7.8986, -9.5681, -8.9506, 4.1038, -0.0768, 0.1011],
    "variance": [1.1075, 0.6705, 0.5651, 1.4489, 1.4656, 1.3084, 0.8046, 0.5977, 1.1842, 0.9402]
})

# Fun√ß√£o de res√≠duos ponderados
def residuals(params, x, y, rho_obs, weights):
    theta, rho = params
    predicted = x * np.cos(theta) + y * np.sin(theta)
    return weights * (predicted - rho_obs)

# Vetores numpy
x = dados["x"].to_numpy()
y = dados["y"].to_numpy()
rho_obs = dados["rho_observed"].to_numpy()
weights = 1 / np.sqrt(dados["variance"].to_numpy())

# Chute inicial dos par√¢metros
initial_guess = [0.5, 0.0]

# Ajuste com m√≠nimos quadrados ponderados
result = least_squares(residuals, x0=initial_guess, args=(x, y, rho_obs, weights))

# Par√¢metros estimados
theta_est, rho_est = result.x

# Exibindo resultado
print(f"Œ∏ estimado: {np.degrees(theta_est):.4f} graus")
print(f"œÅ estimado: {rho_est:.4f}")

"""### Res√≠duos"""

# C√°lculo dos res√≠duos n√£o ponderados
residuos_nao_ponderados = x * np.cos(theta_est) + y * np.sin(theta_est) - rho_est

# C√°lculo dos res√≠duos ponderados
residuos_ponderados = weights * residuos_nao_ponderados

# Criando um DataFrame para exibir lado a lado
residuos_df = pd.DataFrame({
    "x": x,
    "y": y,
    "rho_observado": rho_obs,
    "rho_estimado": x * np.cos(theta_est) + y * np.sin(theta_est),
    "res√≠duo": residuos_nao_ponderados,
    "res√≠duo_ponderado": residuos_ponderados
})

# Exibindo os res√≠duos
display(residuos_df.round(4))

"""## Parametros Estimados

### Par√¢metros Estimados

- **$\theta_{est}$ (rad)**:
"""

print(f"Œ∏est (rad): {theta_est:.4f}")

"""- **$\theta_{est}$ (graus)**:

"""

print(f"Œ∏est (graus): {np.degrees(theta_est):.2f}¬∞")

"""- **$\rho_{est}$**:

"""

print(f"œÅest: {rho_est:.4f}")

"""- **MSE (Erro Quadr√°tico M√©dio)**:"""

# Erro Quadr√°tico M√©dio (MSE)
mse = np.mean(residuos_nao_ponderados ** 2)
print(f"MSE (Erro Quadr√°tico M√©dio): {mse:.4f}")

"""## Res√≠duos Padronizados:"""

# C√°lculo dos res√≠duos padronizados
residuos_padronizados = residuos_nao_ponderados / np.sqrt(dados["variance"].to_numpy())

# Adicionando ao DataFrame
residuos_df["res√≠duo_padronizado"] = residuos_padronizados

# Exibindo os res√≠duos padronizados
display(residuos_df[["x", "y", "res√≠duo", "res√≠duo_padronizado"]].round(4))

"""### Res√≠duos Padronizados

Os res√≠duos padronizados s√£o obtidos dividindo-se cada res√≠duo pelo desvio padr√£o (raiz da vari√¢ncia) associado √† observa√ß√£o:

$$\text{Res√≠duo Padronizado}_i = \frac{F_i}{\sqrt{\text{Var}_i}}$$

Eles permitem identificar **valores discrepantes**: geralmente, valores maiores que 2 ou menores que -2 em m√≥dulo indicam poss√≠veis outliers.

## Interpreta√ß√£o:

### Res√≠duos Padronizados: Algum dos res√≠duos padronizados ultrapassou os limites de ¬±2?
"""

# Verifica se algum res√≠duo padronizado ultrapassou ¬±2
outliers = residuos_df[np.abs(residuos_padronizados) > 2]

# Exibe os casos se existirem
if not outliers.empty:
    print("‚ö†Ô∏è Observa√ß√µes com res√≠duos padronizados fora dos limites ¬±2:")
    display(outliers[["x", "y", "res√≠duo_padronizado"]].round(4))
else:
    display("‚úÖ Nenhum res√≠duo padronizado ultrapassou os limites de ¬±2.")

"""### Existe utliers presentes nos dados fornecidos?

R: Existe outliers presentes nos dados fornecidos?

**Sim**, a an√°lise dos **res√≠duos padronizados** revelou a presen√ßa de **v√°rios outliers**.

Foram consideradas como potenciais observa√ß√µes discrepantes aquelas com res√≠duos padronizados com m√≥dulo superior a 2 $(|r_i| > 2$). No conjunto de dados analisado, **8 das 10 observa√ß√µes** ultrapassaram esse limite, indicando que esses pontos est√£o significativamente distantes da reta ajustada pelo modelo.

Esses outliers podem ter diferentes origens, como:

- Erros de medi√ß√£o (instrumentos imprecisos ou mal calibrados),
- Variabilidade natural dos dados,
- Falhas na modelagem ou necessidade de segmenta√ß√£o (por exemplo, mais de uma reta pode representar melhor os dados).

**Conclus√£o:** H√° **fortes evid√™ncias de outliers**, e uma investiga√ß√£o adicional √© recomendada para compreender seu impacto e, se necess√°rio, aplicar t√©cnicas de ajuste robusto ou reavaliar a consist√™ncia dos dados.

## Conclus√£o:

**Res√≠duos Padronizados**

A an√°lise dos res√≠duos padronizados demonstrou que a maioria das observa√ß√µes apresenta valores com m√≥dulo superior a 2. Isso indica que os dados n√£o est√£o perfeitamente alinhados com o modelo ajustado, e h√° desvios significativos em diversas observa√ß√µes.

Esse comportamento sugere que o modelo pode estar sofrendo influ√™ncia de valores extremos ou que a variabilidade dos dados n√£o √© totalmente explicada pela reta estimada.

Recomenda-se investigar a natureza dessas discrep√¢ncias e considerar o uso de t√©cnicas de ajuste robusto.

**Outliers**:

A presen√ßa de **outliers** foi confirmada com base nos res√≠duos padronizados. Foram identificadas **8 observa√ß√µes com $|r_i| > 2$**, o que representa uma parcela significativa do conjunto de dados.

Esses outliers podem comprometer a qualidade do ajuste, influenciar a inclina√ß√£o da reta e distorcer as estimativas dos par√¢metros. √â importante considerar:

- A verifica√ß√£o das observa√ß√µes para poss√≠veis erros;
- A aplica√ß√£o de t√©cnicas que sejam menos sens√≠veis a outliers, como regress√£o robusta;
- Ou segmentar os dados, caso eles representem popula√ß√µes diferentes.

A presen√ßa de outliers justifica uma abordagem mais cuidadosa na interpreta√ß√£o dos resultados.
"""